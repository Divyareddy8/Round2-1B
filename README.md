# ğŸ“˜ Round 1B â€“ Persona-Driven Document Intelligence  
**Connecting the Dots Challenge**

## ğŸ§  Overview

In Round 1B, we build an intelligent document analyst that extracts and ranks the most relevant sections from a collection of PDFs based on a specific **persona** and a **job-to-be-done**. This solution personalizes reading by surfacing content that truly matters to the user.

The pipeline combines structured outline extraction (from Round 1A), sentence embeddings for relevance ranking, and lightweight local summarization using an offline LLM.

---

## ğŸš€ Architecture & Components

1. **Input PDFs** â€” A folder of 3â€“10 PDFs related to a task.
2. **Round 1A Outline Extractor** â€” Extracts document structure (Title, H1, H2, H3) with page numbers.
3. **Embedding-based Relevance Ranking**
   - Uses **BAAI bge-small-en** sentence embedding model.
   - Computes cosine similarity between heading text and persona+job.
4. **Lightweight LLM Summarization**
   - Uses **Phi 1.5 (GGUF format)** â€” a 1GB quantized model running offline.
   - Summarizes top-ranked sections.

---


## ğŸ³ Docker Instructions

### ğŸ”§ Build the Docker Image (Requires Internet)

```bash
docker build --platform linux/amd64 -t headingclassifier:1b .
```

### â–¶ï¸ Run the Container (Offline Mode)

```bash
docker run --rm \
  -v $(pwd)/input:/app/input \
  -v $(pwd)/output:/app/output \
  --network none \
  headingclassifier:1b
```

* ğŸ“‚ All PDFs in `/input` are automatically processed.
* ğŸ“„ JSON output will be saved to `/output`.

---

## âœ… Requirements & Constraints Met

| Constraint              | Status      |
| ----------------------- | ----------- |
| CPU-only                | âœ…           |
| Model size â‰¤ 1GB        | âœ…           |
| No internet at runtime  | âœ…           |
| Execution time â‰¤ 60s    | âœ…           |
| Multilingual extensible | âš™ï¸ (future) |

---

## ğŸ“Œ 

* BAAI bge-small-en model is used for embedding-based ranking.
* Phi 1.5 LLM (quantized GGUF) runs fully offline using `ggml` or `ctransformers`.
* No hardcoded file logic. Fully generalizable across domains and personas.

---
